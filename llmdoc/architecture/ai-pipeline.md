# AI ç®¡é“è®¾è®¡

## ç®¡é“æ¦‚è§ˆ (Phase 2.1 æ¶æ„ - OpenAI å…¼å®¹ API)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Engram AI Pipeline - VLM æ¶æ„ï¼ˆOpenAI å…¼å®¹ APIï¼‰              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

              è¾“å…¥                      å¤„ç†                        è¾“å‡º
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   å›¾åƒ â”€â–ºâ”‚  OpenAI  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   Qwen3-VL   â”‚â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ ScreenDescriptionâ”‚
         â”‚  å…¼å®¹    â”‚            â”‚   (æˆ–å…¶ä»–)    â”‚        â”‚ {summary,        â”‚
         â”‚  API     â”‚            â”‚   VLM æ¨¡å‹   â”‚        â”‚  text_content,   â”‚
         â”‚          â”‚            â”‚ (é€šè¿‡HTTP)   â”‚        â”‚  detected_app,   â”‚
         â”‚  åç«¯:   â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  activity_type,  â”‚
         â”‚ Ollama   â”‚                   â”‚                 â”‚  entities,       â”‚
         â”‚ vLLM     â”‚                   â–¼                 â”‚  confidence}     â”‚
         â”‚ LM       â”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Studio   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   MiniLM     â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   æ–‡æœ¬ â”€â–ºâ”‚ OpenAI   â”‚            â”‚   L6-v2      â”‚â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  æ–‡æœ¬å‘é‡        â”‚
         â”‚ Together â”‚            â”‚ (åµŒå…¥)       â”‚        â”‚  (384d)          â”‚
         â”‚ AI ç­‰    â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚          â”‚                   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â–¼
                                   [å‘é‡æœç´¢]
                                        â–¼
                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚ è¯­ä¹‰ç›¸å…³æ€§æ’åº    â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## æ ¸å¿ƒæµç¨‹å˜æ›´ (PaddleOCR â†’ VLM)

### ç§»é™¤çš„ç»„ä»¶
- **PaddleOCR** (ONNX): å¤šæ­¥éª¤çš„æ–‡æœ¬æ£€æµ‹å’Œè¯†åˆ«æµç¨‹
- **ONNX Runtime** (`ort` crate): ä¸å†éœ€è¦æœ¬åœ°æ¨ç†æ¡†æ¶
- **ndarray** crate: å¼ é‡æ“ä½œåº“
- **llama-server sidecar**: ä¸å†æ†ç»‘ï¼Œæ”¹ä¸ºé…ç½®å¤–éƒ¨ OpenAI å…¼å®¹ API

### æ–°å¢çš„ç»„ä»¶
- **VLM æ”¯æŒ**: é€šè¿‡ OpenAI å…¼å®¹ API è°ƒç”¨ä»»ä½• VLM æ¨¡å‹
  - æ”¯æŒçš„åç«¯: Ollamaã€vLLMã€LM Studioã€OpenAIã€Together AIã€OpenRouter ç­‰
  - æ¨¡å‹ç¤ºä¾‹: Qwen3-VL-4Bã€GPT-4Vã€Claude Vision ç­‰
- **VlmEngine**: Rust æ¨¡å—ï¼Œç®¡ç† OpenAI å…¼å®¹ API é€šä¿¡
  - æ–‡ä»¶: `src-tauri/src/ai/vlm.rs` (~400 è¡Œ)
  - æ ¸å¿ƒç»“æ„: `VlmEngine`, `VlmConfig`, `ScreenDescription`
  - HTTP å®¢æˆ·ç«¯: reqwest 0.12
  - é…ç½®é¢„è®¾: `VlmConfig::ollama()`, `VlmConfig::openai()`, `VlmConfig::custom()`

## æ¨¡å‹æ¸…å•

| æ¨¡å‹ | ç”¨é€” | æ”¯æŒ | åç«¯ç¤ºä¾‹ | çŠ¶æ€ |
|------|-----|------|---------|------|
| Qwen3-VL-4B | å±å¹•ç†è§£ + OCR | OpenAI å…¼å®¹ API | Ollamaã€vLLMã€LM Studio | âœ… å·²é›†æˆ |
| GPT-4V | å±å¹•ç†è§£ï¼ˆé«˜ç²¾åº¦ï¼‰ | OpenAI API | OpenAI | âœ… å·²é›†æˆ |
| Claude Vision | å±å¹•ç†è§£ | æœªæ¥æ”¯æŒ | Anthropic | ğŸ“‹ è®¡åˆ’ |
| all-MiniLM-L6-v2 | æ–‡æœ¬åµŒå…¥ | ONNX | æœ¬åœ°æ¨ç† | âœ… å·²é›†æˆ |
| CLIP-ViT-B-32 | è§†è§‰åµŒå…¥ (å¯é€‰) | ONNX | æœ¬åœ°æ¨ç† | ğŸ“‹ å¯é€‰ |
| DeBERTa-v3-xsmall-NLI | é›¶æ ·æœ¬åˆ†ç±» | ONNX | æœ¬åœ°æ¨ç† | ğŸ“‹ å¾…é›†æˆ |

## VLM ç®¡é“è¯¦ç»†è®¾è®¡

### æ•°æ®æµ

```
æˆªå›¾ (JPEG)
    â†“
[Base64 ç¼–ç ]
    â†“
OpenAI å…¼å®¹ API POST /chat/completions
    â”œâ”€ model: é…ç½®çš„æ¨¡å‹åç§°
    â”œâ”€ messages: [{ role: "user", content: [{ type: "image_url", ... }] }]
    â”œâ”€ max_tokens: 512 (å¯é…ç½®)
    â””â”€ temperature: 0.3 (å¯é…ç½®)
    â†“
[JSON å“åº”è§£æ]
    â†“
ScreenDescription {
    summary: String,           // å±å¹•æ´»åŠ¨æ€»ç»“
    text_content: Option<String>,  // æå–çš„æ‰€æœ‰æ–‡æœ¬
    detected_app: Option<String>,  // æ£€æµ‹åˆ°çš„åº”ç”¨åç§°
    activity_type: Option<String>, // æ´»åŠ¨ç±»åˆ« (coding/browsing/etc)
    entities: Vec<String>,     // æå–çš„å®ä½“ (é¡¹ç›®å/æ–‡ä»¶/URL)
    confidence: f32,           // ç½®ä¿¡åº¦ (0.0-1.0)
}
    â†“
[MiniLM åµŒå…¥]
    â†“
text_embedding (384d)
    â†“
[å­˜å‚¨åˆ° SQLite]
```

### VlmConfig é…ç½®

```rust
pub struct VlmConfig {
    /// API ç«¯ç‚¹ (å¦‚ http://localhost:11434/v1)
    pub endpoint: String,
    /// æ¨¡å‹åç§° (å¦‚ qwen3-vl:4b)
    pub model: String,
    /// API å¯†é’¥ (è¿œç¨‹æœåŠ¡éœ€è¦)
    pub api_key: Option<String>,
    /// æœ€å¤§è¾“å‡º tokens (é»˜è®¤ 512)
    pub max_tokens: u32,
    /// æ¸©åº¦å‚æ•° (é»˜è®¤ 0.3)
    pub temperature: f32,
}

// ä¾¿åˆ©é¢„è®¾
let ollama_config = VlmConfig::ollama("qwen3-vl:4b");
let openai_config = VlmConfig::openai("sk-...", "gpt-4v");
let custom_config = VlmConfig::custom("http://...", "model", Some("key"));
```

### VlmEngine æ ¸å¿ƒæ¥å£

```rust
pub struct VlmEngine {
    config: VlmConfig,
    client: reqwest::Client,
    is_ready: bool,
}

impl VlmEngine {
    // åˆ›å»ºæ–°å¼•æ“
    pub fn new(config: VlmConfig) -> Self;

    // åˆå§‹åŒ–ï¼ˆéªŒè¯è¿æ¥ï¼‰
    pub async fn initialize(&mut self) -> Result<()>;

    // è‡ªåŠ¨æ£€æµ‹å¯ç”¨çš„æœ¬åœ°æœåŠ¡
    pub async fn auto_detect() -> Result<Self>;

    // æ£€æŸ¥æ˜¯å¦å°±ç»ª
    pub fn is_running(&self) -> bool;

    // åˆ†æå±å¹•æˆªå›¾
    pub async fn analyze_screen(&self, image: &RgbImage) -> Result<ScreenDescription>;

    // è·å–ç”¨äºåµŒå…¥çš„æ–‡æœ¬
    pub fn get_text_for_embedding(desc: &ScreenDescription) -> String;

    // è·å–åç«¯åç§°
    pub fn backend_name(&self) -> String;
}

#[derive(Deserialize, Serialize)]
pub struct ScreenDescription {
    pub summary: String,
    pub text_content: Option<String>,
    pub detected_app: Option<String>,
    pub activity_type: Option<String>,
    pub entities: Vec<String>,
    pub confidence: f32,
}
```

### æ”¯æŒçš„åç«¯

| åç«¯ | ç«¯ç‚¹ç¤ºä¾‹ | å®‰è£…æ–¹å¼ | æ¨¡å‹æ”¯æŒ |
|------|---------|---------|---------|
| **Ollama** | http://localhost:11434/v1 | [ollama.com](https://ollama.com/download) | Qwen3-VLã€Llamaã€Mistral ç­‰ |
| **vLLM** | http://localhost:8000/v1 | `pip install vllm` | æ‰€æœ‰ HuggingFace æ¨¡å‹ |
| **LM Studio** | http://localhost:1234/v1 | [lmstudio.ai](https://lmstudio.ai/) | æœ¬åœ° GGUF æ¨¡å‹ |
| **OpenAI** | https://api.openai.com/v1 | API Key | GPT-4Vã€GPT-4o |
| **Together AI** | https://api.together.xyz/v1 | API Key | Qwenã€Llamaã€Mistral ç­‰ |
| **OpenRouter** | https://openrouter.ai/api/v1 | API Key | 300+ æ¨¡å‹èšåˆ |

### å¿«é€Ÿå¼€å§‹ç¤ºä¾‹

```rust
use engram_lib::ai::vlm::{VlmEngine, VlmConfig};

// æ–¹å¼ 1: è‡ªåŠ¨æ£€æµ‹æœ¬åœ°æœåŠ¡
let mut engine = VlmEngine::auto_detect().await?;
engine.initialize().await?;

// æ–¹å¼ 2: æŒ‡å®š Ollama é…ç½®
let mut engine = VlmEngine::new(VlmConfig::ollama("qwen3-vl:4b"));
engine.initialize().await?;

// æ–¹å¼ 3: ä½¿ç”¨ OpenAI
let mut engine = VlmEngine::new(
    VlmConfig::openai("sk-...", "gpt-4v")
);
engine.initialize().await?;

// åˆ†ææˆªå›¾
let desc = engine.analyze_screen(&image).await?;
println!("{}", desc.summary);
println!("App: {:?}", desc.detected_app);
println!("Confidence: {}", desc.confidence);
```

## æ–°å¢ä¾èµ–

```toml
[dependencies]
# HTTP å®¢æˆ·ç«¯
reqwest = { version = "0.12", features = ["json"] }

# å›¾ç‰‡ç¼–ç  (Base64)
base64 = "0.22"
```

## ç§»é™¤çš„ä¾èµ–

```toml
# å·²ç§»é™¤ï¼ˆä¸å†éœ€è¦ï¼‰
# ort = "2.0.0-rc.9"        # ONNX Runtime
# ndarray = "0.16"          # å¼ é‡æ“ä½œ
# tokenizers = "0.19"       # OCR åå¤„ç†
```

## æ¶æ„ä¼˜åŠ¿

### 1. çµæ´»æ€§
- æ”¯æŒä»»ä½• OpenAI å…¼å®¹ API
- æ— éœ€æ†ç»‘æ¨ç†æœåŠ¡å™¨
- ç”¨æˆ·å¯é€‰æ‹©æœ¬åœ°æˆ–äº‘ç«¯æœåŠ¡

### 2. ç®€åŒ–ç®¡é“
**ä¹‹å‰** (PaddleOCR â†’ åµŒå…¥ â†’ æœç´¢):
```
æˆªå›¾ â†’ PP-OCRv4-det (300ms) â†’ æ–‡æœ¬æ¡† â†’ PP-OCRv4-rec (200ms) â†’ æ–‡æœ¬ â†’ MiniLM (100ms) â†’ å‘é‡
```

**ç°åœ¨** (VLM â†’ åµŒå…¥ â†’ æœç´¢):
```
æˆªå›¾ â†’ VLM (2-10s) â†’ ç»“æ„åŒ–æè¿° + æ–‡æœ¬ â†’ MiniLM (100ms) â†’ å‘é‡
```

### 3. æ›´æ™ºèƒ½
- VLM ä¸ä»…æå–æ–‡æœ¬ï¼Œè¿˜èƒ½ç†è§£ä¸Šä¸‹æ–‡
- è‡ªåŠ¨æ£€æµ‹åº”ç”¨å’Œæ´»åŠ¨ç±»å‹
- æå–è¯­ä¹‰ç›¸å…³çš„å®ä½“å’Œç½®ä¿¡åº¦

### 4. å¼€æ”¾ç”Ÿæ€
- æ”¯æŒæœ¬åœ°å¼€æºæ¨¡å‹ï¼ˆæˆæœ¬ä½ã€éšç§å¥½ï¼‰
- æ”¯æŒäº‘ç«¯æ¨¡å‹ï¼ˆç²¾åº¦é«˜ã€å“åº”å¿«ï¼‰
- è‡ªåŠ¨æ£€æµ‹æœ¬åœ°æœåŠ¡ï¼Œå¼€ç®±å³ç”¨

## å½“å‰å®ç°çŠ¶æ€ (Phase 2.1 - æ¶æ„å‡çº§å®Œæˆ)

- **æ–‡ä»¶**: `src-tauri/src/ai/vlm.rs` (~400 è¡Œ)
- **æ ¸å¿ƒç»“æ„**:
  - `VlmEngine` - OpenAI å…¼å®¹ API å¼•æ“
  - `VlmConfig` - çµæ´»çš„é…ç½®ç³»ç»Ÿ
  - `ScreenDescription` - ç»“æ„åŒ–å±å¹•æè¿°

- **å…³é”®æ–¹æ³•**:
  - `new(config)` - åˆå§‹åŒ– VLM å¼•æ“
  - `auto_detect()` - è‡ªåŠ¨æ£€æµ‹å¯ç”¨æœåŠ¡
  - `initialize()` - éªŒè¯è¿æ¥
  - `analyze_screen(image)` - æ‰§è¡Œå±å¹•ç†è§£
  - `get_text_for_embedding()` - è·å–åµŒå…¥æ–‡æœ¬

- **æ”¯æŒç‰¹æ€§**:
  - å¤šåç«¯æ”¯æŒï¼ˆæœ¬åœ° + äº‘ç«¯ï¼‰
  - API å¯†é’¥ç®¡ç†
  - å›¾ç‰‡ç¼©æ”¾ä¼˜åŒ–
  - JSON å“åº”è‡ªåŠ¨è§£æ
  - ç½®ä¿¡åº¦è¯„åˆ†

---

## åµŒå…¥ç®¡é“è®¾è®¡

### åŒåç«¯æ¶æ„

åµŒå…¥æ¨¡å—æ”¯æŒä¸¤ç§åç«¯ï¼Œä¼˜å…ˆä½¿ç”¨ OpenAI å…¼å®¹ APIï¼Œæ— é…ç½®æˆ–è¿æ¥å¤±è´¥æ—¶å›é€€åˆ°æœ¬åœ°æ¨¡å‹ï¼š

```
é…ç½®æ£€æŸ¥
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ endpoint å·²é…ç½®?                              â”‚
â”‚   â”œâ”€ Yes â†’ å°è¯• OpenAI å…¼å®¹ API              â”‚
â”‚   â”‚         â”œâ”€ æˆåŠŸ â†’ ä½¿ç”¨ API åµŒå…¥          â”‚
â”‚   â”‚         â””â”€ å¤±è´¥ â†’ å›é€€åˆ°æœ¬åœ°             â”‚
â”‚   â””â”€ No  â†’ ä½¿ç”¨æœ¬åœ° fastembed               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### EmbeddingConfig é…ç½®

```rust
pub struct EmbeddingConfig {
    /// API ç«¯ç‚¹ï¼ˆNone = ä½¿ç”¨æœ¬åœ°ï¼‰
    pub endpoint: Option<String>,
    /// æ¨¡å‹åç§°
    pub model: String,
    /// API å¯†é’¥
    pub api_key: Option<String>,
}

// é¢„è®¾é…ç½®
let local = EmbeddingConfig::local();                    // æœ¬åœ° MiniLM
let openai = EmbeddingConfig::openai("sk-...");          // OpenAI API
let ollama = EmbeddingConfig::ollama("nomic-embed-text"); // Ollama
let custom = EmbeddingConfig::custom(endpoint, model, api_key);
```

### TextEmbedder æ ¸å¿ƒæ¥å£

```rust
pub struct TextEmbedder {
    config: EmbeddingConfig,
    backend: EmbeddingBackend,  // OpenAiCompatible | Local
    client: reqwest::Client,
    local_model: Option<fastembed::TextEmbedding>,
}

impl TextEmbedder {
    // åˆ›å»ºåµŒå…¥å™¨
    pub fn new() -> Self;                              // é»˜è®¤æœ¬åœ°
    pub fn with_config(config: EmbeddingConfig) -> Self;

    // åˆå§‹åŒ–ï¼ˆAPI å¤±è´¥è‡ªåŠ¨å›é€€åˆ°æœ¬åœ°ï¼‰
    pub async fn initialize(&mut self) -> Result<()>;

    // åµŒå…¥æ–‡æœ¬
    pub async fn embed(&self, text: &str) -> Result<Vec<f32>>;
    pub async fn embed_batch(&self, texts: &[String]) -> Result<Vec<Vec<f32>>>;

    // åŒæ­¥ç‰ˆæœ¬ï¼ˆä»…æœ¬åœ°æ¨¡å¼ï¼‰
    pub fn embed_sync(&self, text: &str) -> Result<Vec<f32>>;

    // è¾…åŠ©æ–¹æ³•
    pub fn backend_name(&self) -> String;
    pub fn embedding_dim(&self) -> usize;
}
```

### æ”¯æŒçš„åµŒå…¥æ¨¡å‹

| åç«¯ | æ¨¡å‹ | ç»´åº¦ | ç‰¹ç‚¹ |
|------|-----|------|------|
| **æœ¬åœ°** | all-MiniLM-L6-v2 | 384 | ç¦»çº¿å¯ç”¨ï¼Œå¿«é€Ÿ |
| **OpenAI** | text-embedding-3-small | 1536 | é«˜è´¨é‡ï¼Œéœ€ API Key |
| **OpenAI** | text-embedding-3-large | 3072 | æœ€é«˜è´¨é‡ |
| **Ollama** | nomic-embed-text | 768 | æœ¬åœ°æœåŠ¡ï¼Œå…è´¹ |
| **Ollama** | mxbai-embed-large | 1024 | æœ¬åœ°é«˜è´¨é‡ |

### å¿«é€Ÿå¼€å§‹ç¤ºä¾‹

```rust
use engram_lib::ai::embedding::{TextEmbedder, EmbeddingConfig};

// æ–¹å¼ 1: æœ¬åœ°æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
let mut embedder = TextEmbedder::new();
embedder.initialize().await?;

// æ–¹å¼ 2: OpenAI API
let mut embedder = TextEmbedder::with_config(
    EmbeddingConfig::openai("sk-...")
);
embedder.initialize().await?;  // å¤±è´¥ä¼šè‡ªåŠ¨å›é€€åˆ°æœ¬åœ°

// æ–¹å¼ 3: Ollama
let mut embedder = TextEmbedder::with_config(
    EmbeddingConfig::ollama("nomic-embed-text")
);
embedder.initialize().await?;

// åµŒå…¥æ–‡æœ¬
let vec = embedder.embed("hello world").await?;
let vecs = embedder.embed_batch(&texts).await?;

println!("Backend: {}", embedder.backend_name());
println!("Dimension: {}", embedder.embedding_dim());
```

### å½“å‰å®ç°çŠ¶æ€ (Phase 2 M2.2 å®Œæˆ)

- **æ–‡ä»¶**: `src-tauri/src/ai/embedding.rs` (~500 è¡Œ)
- **æ ¸å¿ƒç»“æ„**:
  - `TextEmbedder` - åŒåç«¯æ–‡æœ¬åµŒå…¥å™¨
  - `EmbeddingConfig` - çµæ´»é…ç½®ç³»ç»Ÿ
  - `EmbeddingQueue` - æ‰¹å¤„ç†é˜Ÿåˆ—

- **å…³é”®ç‰¹æ€§**:
  - OpenAI å…¼å®¹ API æ”¯æŒ
  - è‡ªåŠ¨å›é€€åˆ°æœ¬åœ°æ¨¡å‹
  - å¼‚æ­¥å’ŒåŒæ­¥ API
  - æ‰¹é‡åµŒå…¥ä¼˜åŒ–

---

## å‘é‡æœç´¢ä¸æ··åˆæœç´¢

### å‘é‡å­˜å‚¨è®¾è®¡

```sql
-- traces è¡¨æ–°å¢å­—æ®µ (M2.2.2 å®Œæˆ)
ALTER TABLE traces ADD COLUMN embedding BLOB;  -- å‘é‡ä»¥ BLOB å½¢å¼å­˜å‚¨

-- å‘é‡æ ¼å¼: ä½¿ç”¨ bincode åºåˆ—åŒ–ä¸ºäºŒè¿›åˆ¶
-- Vec<f32> -> bincode ç¼–ç  -> BLOB
```

### å‘é‡æœç´¢å®ç° (M2.2.2)

å‚è§ `llmdoc/architecture/data-flow.md` ä¸­çš„å‘é‡æœç´¢éƒ¨åˆ†ã€‚

### æ··åˆæœç´¢ - RRF èåˆ (M2.2.3 å®Œæˆ)

ç»“åˆå…¨æ–‡æœç´¢ (FTS5) å’Œå‘é‡æœç´¢ï¼Œä½¿ç”¨ RRF (Reciprocal Rank Fusion) èåˆç®—æ³•è¿›è¡Œç»“æœæ’åºã€‚

---

## æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 1. è‡ªåŠ¨æ£€æµ‹ + é»˜è®¤é…ç½®

```rust
// è‡ªåŠ¨æ£€æµ‹æœ¬åœ°æœåŠ¡ï¼Œå¼€ç®±å³ç”¨
let mut engine = VlmEngine::auto_detect().await.expect(
    "No local VLM service detected.\n\
     Please install Ollama: https://ollama.com/download"
);
engine.initialize().await?;
```

### 2. æ‰¹å¤„ç†

```rust
// æ¯ 10 å¸§è¿›è¡Œä¸€æ¬¡æ‰¹é‡åµŒå…¥
const EMBEDDING_BATCH_SIZE: usize = 10;

impl EmbeddingQueue {
    fn enqueue(&mut self, text: String, callback: Callback) {
        self.queue.push((text, callback));

        if self.queue.len() >= EMBEDDING_BATCH_SIZE {
            self.flush();
        }
    }

    fn flush(&mut self) {
        let texts: Vec<_> = self.queue.iter().map(|(t, _)| t.clone()).collect();
        let embeddings = self.embedder.embed_batch(&texts).unwrap();

        for ((_, callback), emb) in self.queue.drain(..).zip(embeddings) {
            callback(emb);
        }
    }
}
```

### 3. ç¡¬ä»¶é€‚é…

| ç¡¬ä»¶é…ç½® | VLM é€‰æ‹© | åµŒå…¥ç²¾åº¦ | æ¨èç”¨é€” |
|---------|---------|---------|---------|
| é«˜ç«¯ (16GB+, GPU) | GPT-4V æˆ– QwenVL-8B | FP32 | é«˜ç²¾åº¦ã€å®æ—¶å¤„ç† |
| ä¸­ç«¯ (8-16GB) | Qwen3-VL-4B (Ollama) | FP32 | å¹³è¡¡æ€§èƒ½å’Œè´¨é‡ |
| ä½ç«¯ (<8GB) | Qwen3-VL-4B Q2_K é‡åŒ– | FP16 | æœ‰é™èµ„æºä¸‹å¯ç”¨ |

### 4. ç¼“å­˜ç­–ç•¥

```rust
// å›¾ç‰‡å“ˆå¸Œç¼“å­˜ï¼Œé¿å…é‡å¤åˆ†æ
struct VlmCache {
    lru: LRUCache<ImageHash, ScreenDescription>,
    max_size: usize,
}

impl VlmCache {
    fn get_or_analyze(&mut self, image: &RgbImage, engine: &VlmEngine) -> Result<ScreenDescription> {
        let hash = hash_image(image);
        if let Some(cached) = self.lru.get(&hash) {
            return Ok(cached.clone());
        }

        let desc = engine.analyze_screen(image).await?;
        self.lru.insert(hash, desc.clone());
        Ok(desc)
    }
}
```
