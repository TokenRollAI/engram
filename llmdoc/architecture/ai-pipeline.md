# AI ç®¡é“è®¾è®¡

## ç®¡é“æ¦‚è§ˆ (Phase 3.2 - å®Œæ•´ AI ç®¡é“ï¼šVLM åˆ†æ + Summary + Chat)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Engram AI Pipeline - VLM åå°è‡ªåŠ¨å¤„ç†ä¸å†…å­˜åˆæˆï¼ˆM3.2 å®Œæ•´ï¼‰      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

[å‰å°æ•è·]              [åå°åˆ†æ]           [å‘¨æœŸåˆæˆ]        [äº¤äº’æŸ¥è¯¢]
  |                       |                    |                  |
  v                       v                    v                  v
  æ•è·æˆªå›¾          VlmTask å®šæ—¶æ‰«æ    SummarizerTask      Chat é¡µé¢
  ä¿å­˜å›¾ç‰‡æ–‡ä»¶    (ocr_text IS NULL)     (15åˆ†é’Ÿä¸€æ¬¡)      (ç”¨æˆ·äº¤äº’)
  (ocr_text=NULL)    |                      |                  |
  |                  v                      v                  v
  |            æ‰¹é‡åŠ è½½æˆªå›¾              æŸ¥è¯¢æœ€è¿‘ traces    è·å–æ—¶é—´èŒƒå›´
  |                |                       |                 åº”ç”¨åˆ—è¡¨
  |                v                       v                  |
  |        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         |
  |        â”‚   OpenAI        â”‚     â”‚  LLM (æ‘˜è¦)   â”‚         |
  |        â”‚   å…¼å®¹ API      â”‚     â”‚              â”‚         |
  |        â”‚ (Ollama/vLLM)   â”‚     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         |
  |        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜            |                 |
  |                 |                     v                 |
  |        ScreenDescription          Summaries            |
  |        {summary, text,            è¡¨æ›´æ–°              |
  |         detected_app,             (content+vector)    |
  |         activity_type,                                |
  |         entities,                                     |
  |         confidence}                                   |
  |                 |                                     |
  |                 v                                     |
  |        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           |
  |        â”‚   MiniLM-L6     â”‚                           |
  |        â”‚   (åµŒå…¥æ¨¡å‹)     â”‚                           |
  |        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           |
  |                 |                                     |
  |                 v                                     v
  |        æ–‡æœ¬å‘é‡ (384d)              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  |                 |                   â”‚ VlmEngine::chat()   â”‚
  |                 |                   â”‚ (çº¯æ–‡æœ¬å¯¹è¯)        â”‚
  |                 |                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  |                 |                            |
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                            |
            |                                    |
            v                                    v
    [æ•°æ®åº“æ›´æ–°]                        ChatResponse
    - traces è¡¨                       {message, sources,
    - traces_vec è™šæ‹Ÿè¡¨                references}
    (KNN å‘é‡æœç´¢)
```

## ä¸‰å¤§æ ¸å¿ƒä»»åŠ¡

### 1. VlmTask - å±å¹•åˆ†æ (M3.1 å®ç°)
- **å‘¨æœŸ**: æ¯ 10 ç§’æ‰«æä¸€æ¬¡
- **è¾“å…¥**: å¾…åˆ†æçš„ traces (ocr_text IS NULL)
- **å¤„ç†**: VLM è§†è§‰ç†è§£ â†’ æ–‡æœ¬æå– â†’ å‘é‡ç”Ÿæˆ
- **è¾“å‡º**: OCR æ•°æ® + åµŒå…¥å‘é‡ â†’ æ•°æ®åº“

### 2. SummarizerTask - å‘¨æœŸæ‘˜è¦ (M3.2 æ–°å¢)
- **å‘¨æœŸ**: æ¯ 15 åˆ†é’Ÿç”Ÿæˆä¸€æ¬¡
- **è¾“å…¥**: æœ€è¿‘çš„ traces é›†åˆ
- **å¤„ç†**: LLM æ‘˜è¦ â†’ ç»“æ„åŒ–æå– â†’ å‘é‡åŒ–
- **è¾“å‡º**: Summaries è¡¨ (content + embedding)

### 3. Chat - äº¤äº’æŸ¥è¯¢ (M3.2 æ–°å¢)
- **è§¦å‘**: ç”¨æˆ·è¾“å…¥æŸ¥è¯¢
- **è¾“å…¥**: æ—¶é—´èŒƒå›´ã€åº”ç”¨è¿‡æ»¤ã€æŸ¥è¯¢æ–‡æœ¬
- **å¤„ç†**: å‘é‡æ£€ç´¢ä¸Šä¸‹æ–‡ â†’ VLM æ–‡æœ¬å¯¹è¯
- **è¾“å‡º**: AI å›å¤ + å¼•ç”¨æ¥æº

---

**é˜¶æ®µ 1 (M2.1)**: OCR â†’ VLM æ›¿æ¢
- ç§»é™¤ PaddleOCR å¤šæ­¥éª¤æµç¨‹
- å¼•å…¥ VLM OpenAI å…¼å®¹ API æ”¯æŒ

**é˜¶æ®µ 2 (M2.5)**: ç”¨æˆ·å¯é…ç½®
- æ·»åŠ  AI é…ç½®ç•Œé¢
- æ”¯æŒå¤šä¸ªåç«¯é€‰æ‹©

**é˜¶æ®µ 3 (M3.1)**: åå°è‡ªåŠ¨å¤„ç† (æ–°å¢)
- åˆ›å»º VlmTask åå°ä»»åŠ¡
- è‡ªåŠ¨å¤„ç†å¾…åˆ†æçš„ traces
- æ— éœ€å‰ç«¯å¹²é¢„

### ç§»é™¤çš„ç»„ä»¶
- **PaddleOCR** (ONNX): å¤šæ­¥éª¤çš„æ–‡æœ¬æ£€æµ‹å’Œè¯†åˆ«æµç¨‹
- **ONNX Runtime** (`ort` crate): ä¸å†éœ€è¦æœ¬åœ°æ¨ç†æ¡†æ¶
- **ndarray** crate: å¼ é‡æ“ä½œåº“
- **llama-server sidecar**: ä¸å†æ†ç»‘ï¼Œæ”¹ä¸ºé…ç½®å¤–éƒ¨ OpenAI å…¼å®¹ API

### æ–°å¢çš„ç»„ä»¶
- **VLM æ”¯æŒ**: é€šè¿‡ OpenAI å…¼å®¹ API è°ƒç”¨ä»»ä½• VLM æ¨¡å‹
  - æ”¯æŒçš„åç«¯: Ollamaã€vLLMã€LM Studioã€OpenAIã€Together AIã€OpenRouter ç­‰
  - æ¨¡å‹ç¤ºä¾‹: Qwen3-VL-4Bã€GPT-4Vã€Claude Vision ç­‰
- **VlmEngine**: Rust æ¨¡å—ï¼Œç®¡ç† OpenAI å…¼å®¹ API é€šä¿¡
  - æ–‡ä»¶: `src-tauri/src/ai/vlm.rs` (~400 è¡Œ)
  - æ ¸å¿ƒç»“æ„: `VlmEngine`, `VlmConfig`, `ScreenDescription`
  - HTTP å®¢æˆ·ç«¯: reqwest 0.12
  - é…ç½®é¢„è®¾: `VlmConfig::ollama()`, `VlmConfig::openai()`, `VlmConfig::custom()`
- **VlmTask åå°ä»»åŠ¡** (M3.1 æ–°å¢): è‡ªåŠ¨å¤„ç†å¾…åˆ†æçš„ traces
  - æ–‡ä»¶: `src-tauri/src/daemon/vlm_task.rs` (~290 è¡Œ)
  - æ ¸å¿ƒç»“æ„: `VlmTask`, `VlmTaskConfig`, `VlmTaskStatus`
  - ç‰¹æ€§: å®šæ—¶æ‰«æã€æ‰¹å¤„ç†ã€å¼‚æ­¥å¤„ç†ã€å¯é…ç½®

## VlmTask åå°å¤„ç†æ¶æ„ (M3.1)

### è®¾è®¡ç›®æ ‡

1. **è‡ªåŠ¨åŒ–** - æ— éœ€å‰ç«¯å¹²é¢„ï¼Œè‡ªåŠ¨å¤„ç†å¾…åˆ†æçš„ traces
2. **å¼‚æ­¥éé˜»å¡** - ä¸å½±å“å‰å°æ•è·æ€§èƒ½
3. **æ‰¹å¤„ç†** - æ”¯æŒæ‰¹é‡å¤„ç†ä»¥ä¼˜åŒ–ååé‡
4. **å¯é…ç½®** - å¤„ç†é—´éš”å’Œæ‰¹å¤„ç†å¤§å°å¯è°ƒæ•´
5. **å®¹é”™** - å•æ¡å¤±è´¥ä¸å½±å“å…¶ä»– traces

### VlmTask ç»“æ„ä½“

```rust
pub struct VlmTask {
    db: Arc<Database>,
    vlm: Arc<RwLock<Option<VlmEngine>>>,
    embedder: Arc<RwLock<TextEmbedder>>,
    config: VlmTaskConfig,
    is_running: Arc<AtomicBool>,
    processed_count: Arc<AtomicU64>,
    failed_count: Arc<AtomicU64>,
    shutdown_tx: Option<mpsc::Sender<()>>,
}

pub struct VlmTaskConfig {
    pub interval_ms: u64,      // å¤„ç†é—´éš”ï¼ˆé»˜è®¤ 10000msï¼‰
    pub batch_size: u32,       // æ‰¹å¤„ç†å¤§å°ï¼ˆé»˜è®¤ 5ï¼‰
    pub enabled: bool,         // æ˜¯å¦å¯ç”¨ï¼ˆé»˜è®¤ trueï¼‰
}

pub struct VlmTaskStatus {
    pub is_running: bool,           // ä»»åŠ¡æ˜¯å¦åœ¨è¿è¡Œ
    pub processed_count: u64,       // æˆåŠŸå¤„ç†çš„ traces æ•°é‡
    pub failed_count: u64,          // å¤„ç†å¤±è´¥çš„ traces æ•°é‡
    pub pending_count: u64,         // å¾…å¤„ç†çš„ traces æ•°é‡
}
```

### æ‰§è¡Œæµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VlmTask::start()               â”‚
â”‚  (åœ¨ AppState åˆå§‹åŒ–æ—¶è°ƒç”¨)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  åˆ›å»º Tokio å¼‚æ­¥ä»»åŠ¡             â”‚
â”‚  è®¾ç½®å®šæ—¶å™¨ (interval_ms)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼ (æ¯ä¸ªå‘¨æœŸ)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ£€æŸ¥ VLM æ˜¯å¦å°±ç»ª               â”‚
â”‚  (is_ready == true)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
      No â”€â”€â”€â”€â”¤â”€â”€â”€â”€â”€â”€â–º è·³è¿‡æœ¬å‘¨æœŸ
             â”‚
             Yes
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æŸ¥è¯¢å¾…åˆ†æçš„ traces             â”‚
â”‚  WHERE ocr_text IS NULL         â”‚
â”‚  LIMIT batch_size               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”œâ”€â”€(æ— å¾…åˆ†æ)â”€â”€â–º è·³è¿‡æœ¬å‘¨æœŸ
             â”‚
             Yes
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  for each trace in pending:     â”‚
â”‚    process_single_trace()       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â”œâ”€â–º åŠ è½½æˆªå›¾æ–‡ä»¶
             â”œâ”€â–º è°ƒç”¨ VLM åˆ†æ
             â”œâ”€â–º æå– ocr_text/ocr_json
             â”œâ”€â–º æ›´æ–°æ•°æ®åº“ OCR æ•°æ®
             â”œâ”€â–º ç”ŸæˆåµŒå…¥å‘é‡
             â””â”€â–º æ›´æ–°æ•°æ®åº“ embedding
```

### å•æ¡ Trace å¤„ç†æµç¨‹

```
Input: Trace { id, image_path, ocr_text=NULL, ... }
  â”‚
  â”œâ”€â–º 1. åŠ è½½æˆªå›¾æ–‡ä»¶
  â”‚      path = db.get_full_path(&trace.image_path)
  â”‚      image = image::open(path).to_rgb8()
  â”‚
  â”œâ”€â–º 2. è°ƒç”¨ VLM åˆ†æ
  â”‚      desc = vlm_engine.analyze_screen(&image).await?
  â”‚      è¿”å› ScreenDescription {
  â”‚        summary: String,
  â”‚        text_content: Option<String>,
  â”‚        detected_app: Option<String>,
  â”‚        activity_type: Option<String>,
  â”‚        entities: Vec<String>,
  â”‚        confidence: f32,
  â”‚      }
  â”‚
  â”œâ”€â–º 3. æå– OCR æ•°æ®
  â”‚      ocr_text = VlmEngine::get_text_for_embedding(&desc)
  â”‚      ocr_json = serde_json::to_string(&desc)
  â”‚
  â”œâ”€â–º 4. æ›´æ–°æ•°æ®åº“ï¼ˆOCR æ•°æ®ï¼‰
  â”‚      db.update_trace_ocr(trace.id, &ocr_text, &ocr_json)?
  â”‚
  â”œâ”€â–º 5. ç”ŸæˆåµŒå…¥å‘é‡
  â”‚      embedding = embedder.embed(&ocr_text).await?
  â”‚      è¿”å› Vec<f32> (384 ç»´)
  â”‚
  â”œâ”€â–º 6. åºåˆ—åŒ–åµŒå…¥å‘é‡
  â”‚      embedding_bytes = embedding.iter()
  â”‚        .flat_map(|f| f.to_le_bytes())
  â”‚        .collect::<Vec<u8>>()
  â”‚
  â”œâ”€â–º 7. æ›´æ–°æ•°æ®åº“ï¼ˆåµŒå…¥å‘é‡ï¼‰
  â”‚      db.update_trace_embedding(trace.id, &embedding_bytes)?
  â”‚
  â””â”€â–º Output: Success (processed_count++)
              æˆ– Error (failed_count++)
```

### ä¸ AppState é›†æˆ

```rust
pub struct AppState {
    pub db: Arc<Database>,
    pub daemon: Arc<RwLock<EngramDaemon>>,
    pub vlm: Arc<RwLock<Option<VlmEngine>>>,
    pub embedder: Arc<RwLock<TextEmbedder>>,
    pub vlm_task: Arc<RwLock<VlmTask>>,  // M3.1 æ–°å¢
}

impl AppState {
    pub async fn new() -> anyhow::Result<Self> {
        // ... åˆå§‹åŒ–å…¶ä»–éƒ¨åˆ† ...

        // åˆ›å»º VlmTaskï¼ˆé»˜è®¤å¯ç”¨ï¼‰
        let vlm_task = Arc::new(RwLock::new(VlmTask::new(
            db.clone(),
            vlm.clone(),
            embedder.clone(),
            VlmTaskConfig::default(),
        )));

        // ... å°è¯•è‡ªåŠ¨åˆå§‹åŒ– AI ...

        // å¦‚æœ VLM åˆå§‹åŒ–æˆåŠŸï¼Œå¯åŠ¨åå°ä»»åŠ¡
        if vlm_initialized {
            let mut task = state.vlm_task.write().await;
            task.start()?;
            info!("VLM background task started");
        }

        Ok(state)
    }
}
```

### æ€§èƒ½ç‰¹æ€§

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| **å¤„ç†é—´éš”** | é»˜è®¤ 10 ç§’ï¼Œå¯é…ç½® |
| **æ‰¹å¤„ç†å¤§å°** | é»˜è®¤ 5ï¼Œå¯é…ç½® |
| **å¼‚æ­¥æ¨¡å¼** | ä½¿ç”¨ Tokioï¼Œä¸é˜»å¡ä¸»çº¿ç¨‹ |
| **å®¹é”™æœºåˆ¶** | å•æ¡å¤±è´¥è®°å½•ï¼Œä½†ç»§ç»­å¤„ç†å…¶ä»– traces |
| **ä¼˜é›…å…³é—­** | æ”¯æŒ shutdown_tx ä¿¡å·ï¼Œå®‰å…¨åœæ­¢ä»»åŠ¡ |
| **çŠ¶æ€ç›‘æ§** | é€šè¿‡ VlmTaskStatus ç›‘æ§å¤„ç†è¿›åº¦ |

## æ¨¡å‹æ¸…å•

| æ¨¡å‹ | ç”¨é€” | æ”¯æŒ | åç«¯ç¤ºä¾‹ | çŠ¶æ€ |
|------|-----|------|---------|------|
| Qwen3-VL-4B | å±å¹•ç†è§£ + OCR | OpenAI å…¼å®¹ API | Ollamaã€vLLMã€LM Studio | âœ… å·²é›†æˆ |
| GPT-4V | å±å¹•ç†è§£ï¼ˆé«˜ç²¾åº¦ï¼‰ | OpenAI API | OpenAI | âœ… å·²é›†æˆ |
| Claude Vision | å±å¹•ç†è§£ | æœªæ¥æ”¯æŒ | Anthropic | ğŸ“‹ è®¡åˆ’ |
| all-MiniLM-L6-v2 | æ–‡æœ¬åµŒå…¥ | ONNX | æœ¬åœ°æ¨ç† | âœ… å·²é›†æˆ |
| CLIP-ViT-B-32 | è§†è§‰åµŒå…¥ (å¯é€‰) | ONNX | æœ¬åœ°æ¨ç† | ğŸ“‹ å¯é€‰ |
| DeBERTa-v3-xsmall-NLI | é›¶æ ·æœ¬åˆ†ç±» | ONNX | æœ¬åœ°æ¨ç† | ğŸ“‹ å¾…é›†æˆ |

## VLM ç®¡é“è¯¦ç»†è®¾è®¡

### æ•°æ®æµ

```
æˆªå›¾ (JPEG)
    â†“
[Base64 ç¼–ç ]
    â†“
OpenAI å…¼å®¹ API POST /chat/completions
    â”œâ”€ model: é…ç½®çš„æ¨¡å‹åç§°
    â”œâ”€ messages: [{ role: "user", content: [{ type: "image_url", ... }] }]
    â”œâ”€ max_tokens: 512 (å¯é…ç½®)
    â””â”€ temperature: 0.3 (å¯é…ç½®)
    â†“
[JSON å“åº”è§£æ]
    â†“
ScreenDescription {
    summary: String,           // å±å¹•æ´»åŠ¨æ€»ç»“
    text_content: Option<String>,  // æå–çš„æ‰€æœ‰æ–‡æœ¬
    detected_app: Option<String>,  // æ£€æµ‹åˆ°çš„åº”ç”¨åç§°
    activity_type: Option<String>, // æ´»åŠ¨ç±»åˆ« (coding/browsing/etc)
    entities: Vec<String>,     // æå–çš„å®ä½“ (é¡¹ç›®å/æ–‡ä»¶/URL)
    confidence: f32,           // ç½®ä¿¡åº¦ (0.0-1.0)
}
    â†“
[MiniLM åµŒå…¥]
    â†“
text_embedding (384d)
    â†“
[å­˜å‚¨åˆ° SQLite]
```

### VlmConfig é…ç½®

```rust
pub struct VlmConfig {
    /// API ç«¯ç‚¹ (å¦‚ http://localhost:11434/v1)
    pub endpoint: String,
    /// æ¨¡å‹åç§° (å¦‚ qwen3-vl:4b)
    pub model: String,
    /// API å¯†é’¥ (è¿œç¨‹æœåŠ¡éœ€è¦)
    pub api_key: Option<String>,
    /// æœ€å¤§è¾“å‡º tokens (é»˜è®¤ 512)
    pub max_tokens: u32,
    /// æ¸©åº¦å‚æ•° (é»˜è®¤ 0.3)
    pub temperature: f32,
}

// ä¾¿åˆ©é¢„è®¾
let ollama_config = VlmConfig::ollama("qwen3-vl:4b");
let openai_config = VlmConfig::openai("sk-...", "gpt-4v");
let custom_config = VlmConfig::custom("http://...", "model", Some("key"));
```

### VlmEngine æ ¸å¿ƒæ¥å£

```rust
pub struct VlmEngine {
    config: VlmConfig,
    client: reqwest::Client,
    is_ready: bool,
}

impl VlmEngine {
    // åˆ›å»ºæ–°å¼•æ“
    pub fn new(config: VlmConfig) -> Self;

    // åˆå§‹åŒ–ï¼ˆéªŒè¯è¿æ¥ï¼‰
    pub async fn initialize(&mut self) -> Result<()>;

    // è‡ªåŠ¨æ£€æµ‹å¯ç”¨çš„æœ¬åœ°æœåŠ¡
    pub async fn auto_detect() -> Result<Self>;

    // æ£€æŸ¥æ˜¯å¦å°±ç»ª
    pub fn is_running(&self) -> bool;

    // åˆ†æå±å¹•æˆªå›¾
    pub async fn analyze_screen(&self, image: &RgbImage) -> Result<ScreenDescription>;

    // è·å–ç”¨äºåµŒå…¥çš„æ–‡æœ¬
    pub fn get_text_for_embedding(desc: &ScreenDescription) -> String;

    // è·å–åç«¯åç§°
    pub fn backend_name(&self) -> String;
}

#[derive(Deserialize, Serialize)]
pub struct ScreenDescription {
    pub summary: String,
    pub text_content: Option<String>,
    pub detected_app: Option<String>,
    pub activity_type: Option<String>,
    pub entities: Vec<String>,
    pub confidence: f32,
}
```

### æ”¯æŒçš„åç«¯

| åç«¯ | ç«¯ç‚¹ç¤ºä¾‹ | å®‰è£…æ–¹å¼ | æ¨¡å‹æ”¯æŒ |
|------|---------|---------|---------|
| **Ollama** | http://localhost:11434/v1 | [ollama.com](https://ollama.com/download) | Qwen3-VLã€Llamaã€Mistral ç­‰ |
| **vLLM** | http://localhost:8000/v1 | `pip install vllm` | æ‰€æœ‰ HuggingFace æ¨¡å‹ |
| **LM Studio** | http://localhost:1234/v1 | [lmstudio.ai](https://lmstudio.ai/) | æœ¬åœ° GGUF æ¨¡å‹ |
| **OpenAI** | https://api.openai.com/v1 | API Key | GPT-4Vã€GPT-4o |
| **Together AI** | https://api.together.xyz/v1 | API Key | Qwenã€Llamaã€Mistral ç­‰ |
| **OpenRouter** | https://openrouter.ai/api/v1 | API Key | 300+ æ¨¡å‹èšåˆ |

### å¿«é€Ÿå¼€å§‹ç¤ºä¾‹

```rust
use engram_lib::ai::vlm::{VlmEngine, VlmConfig};

// æ–¹å¼ 1: è‡ªåŠ¨æ£€æµ‹æœ¬åœ°æœåŠ¡
let mut engine = VlmEngine::auto_detect().await?;
engine.initialize().await?;

// æ–¹å¼ 2: æŒ‡å®š Ollama é…ç½®
let mut engine = VlmEngine::new(VlmConfig::ollama("qwen3-vl:4b"));
engine.initialize().await?;

// æ–¹å¼ 3: ä½¿ç”¨ OpenAI
let mut engine = VlmEngine::new(
    VlmConfig::openai("sk-...", "gpt-4v")
);
engine.initialize().await?;

// åˆ†ææˆªå›¾
let desc = engine.analyze_screen(&image).await?;
println!("{}", desc.summary);
println!("App: {:?}", desc.detected_app);
println!("Confidence: {}", desc.confidence);
```

## æ–°å¢ä¾èµ–

```toml
[dependencies]
# HTTP å®¢æˆ·ç«¯
reqwest = { version = "0.12", features = ["json"] }

# å›¾ç‰‡ç¼–ç  (Base64)
base64 = "0.22"
```

## ç§»é™¤çš„ä¾èµ–

```toml
# å·²ç§»é™¤ï¼ˆä¸å†éœ€è¦ï¼‰
# ort = "2.0.0-rc.9"        # ONNX Runtime
# ndarray = "0.16"          # å¼ é‡æ“ä½œ
# tokenizers = "0.19"       # OCR åå¤„ç†
```

## æ¶æ„ä¼˜åŠ¿

### 1. çµæ´»æ€§
- æ”¯æŒä»»ä½• OpenAI å…¼å®¹ API
- æ— éœ€æ†ç»‘æ¨ç†æœåŠ¡å™¨
- ç”¨æˆ·å¯é€‰æ‹©æœ¬åœ°æˆ–äº‘ç«¯æœåŠ¡

### 2. ç®€åŒ–ç®¡é“
**ä¹‹å‰** (PaddleOCR â†’ åµŒå…¥ â†’ æœç´¢):
```
æˆªå›¾ â†’ PP-OCRv4-det (300ms) â†’ æ–‡æœ¬æ¡† â†’ PP-OCRv4-rec (200ms) â†’ æ–‡æœ¬ â†’ MiniLM (100ms) â†’ å‘é‡
```

**ç°åœ¨** (VLM â†’ åµŒå…¥ â†’ æœç´¢):
```
æˆªå›¾ â†’ VLM (2-10s) â†’ ç»“æ„åŒ–æè¿° + æ–‡æœ¬ â†’ MiniLM (100ms) â†’ å‘é‡
```

### 3. æ›´æ™ºèƒ½
- VLM ä¸ä»…æå–æ–‡æœ¬ï¼Œè¿˜èƒ½ç†è§£ä¸Šä¸‹æ–‡
- è‡ªåŠ¨æ£€æµ‹åº”ç”¨å’Œæ´»åŠ¨ç±»å‹
- æå–è¯­ä¹‰ç›¸å…³çš„å®ä½“å’Œç½®ä¿¡åº¦

### 4. å¼€æ”¾ç”Ÿæ€
- æ”¯æŒæœ¬åœ°å¼€æºæ¨¡å‹ï¼ˆæˆæœ¬ä½ã€éšç§å¥½ï¼‰
- æ”¯æŒäº‘ç«¯æ¨¡å‹ï¼ˆç²¾åº¦é«˜ã€å“åº”å¿«ï¼‰
- è‡ªåŠ¨æ£€æµ‹æœ¬åœ°æœåŠ¡ï¼Œå¼€ç®±å³ç”¨

## å½“å‰å®ç°çŠ¶æ€ (Phase 2.1 - æ¶æ„å‡çº§å®Œæˆ)

- **æ–‡ä»¶**: `src-tauri/src/ai/vlm.rs` (~400 è¡Œ)
- **æ ¸å¿ƒç»“æ„**:
  - `VlmEngine` - OpenAI å…¼å®¹ API å¼•æ“
  - `VlmConfig` - çµæ´»çš„é…ç½®ç³»ç»Ÿ
  - `ScreenDescription` - ç»“æ„åŒ–å±å¹•æè¿°

- **å…³é”®æ–¹æ³•**:
  - `new(config)` - åˆå§‹åŒ– VLM å¼•æ“
  - `auto_detect()` - è‡ªåŠ¨æ£€æµ‹å¯ç”¨æœåŠ¡
  - `initialize()` - éªŒè¯è¿æ¥
  - `analyze_screen(image)` - æ‰§è¡Œå±å¹•ç†è§£
  - `get_text_for_embedding()` - è·å–åµŒå…¥æ–‡æœ¬

- **æ”¯æŒç‰¹æ€§**:
  - å¤šåç«¯æ”¯æŒï¼ˆæœ¬åœ° + äº‘ç«¯ï¼‰
  - API å¯†é’¥ç®¡ç†
  - å›¾ç‰‡ç¼©æ”¾ä¼˜åŒ–
  - JSON å“åº”è‡ªåŠ¨è§£æ
  - ç½®ä¿¡åº¦è¯„åˆ†

---

## åµŒå…¥ç®¡é“è®¾è®¡

### åŒåç«¯æ¶æ„

åµŒå…¥æ¨¡å—æ”¯æŒä¸¤ç§åç«¯ï¼Œä¼˜å…ˆä½¿ç”¨ OpenAI å…¼å®¹ APIï¼Œæ— é…ç½®æˆ–è¿æ¥å¤±è´¥æ—¶å›é€€åˆ°æœ¬åœ°æ¨¡å‹ï¼š

```
é…ç½®æ£€æŸ¥
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ endpoint å·²é…ç½®?                              â”‚
â”‚   â”œâ”€ Yes â†’ å°è¯• OpenAI å…¼å®¹ API              â”‚
â”‚   â”‚         â”œâ”€ æˆåŠŸ â†’ ä½¿ç”¨ API åµŒå…¥          â”‚
â”‚   â”‚         â””â”€ å¤±è´¥ â†’ å›é€€åˆ°æœ¬åœ°             â”‚
â”‚   â””â”€ No  â†’ ä½¿ç”¨æœ¬åœ° fastembed               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### EmbeddingConfig é…ç½®

```rust
pub struct EmbeddingConfig {
    /// API ç«¯ç‚¹ï¼ˆNone = ä½¿ç”¨æœ¬åœ°ï¼‰
    pub endpoint: Option<String>,
    /// æ¨¡å‹åç§°
    pub model: String,
    /// API å¯†é’¥
    pub api_key: Option<String>,
}

// é¢„è®¾é…ç½®
let local = EmbeddingConfig::local();                    // æœ¬åœ° MiniLM
let openai = EmbeddingConfig::openai("sk-...");          // OpenAI API
let ollama = EmbeddingConfig::ollama("nomic-embed-text"); // Ollama
let custom = EmbeddingConfig::custom(endpoint, model, api_key);
```

### TextEmbedder æ ¸å¿ƒæ¥å£

```rust
pub struct TextEmbedder {
    config: EmbeddingConfig,
    backend: EmbeddingBackend,  // OpenAiCompatible | Local
    client: reqwest::Client,
    local_model: Option<fastembed::TextEmbedding>,
}

impl TextEmbedder {
    // åˆ›å»ºåµŒå…¥å™¨
    pub fn new() -> Self;                              // é»˜è®¤æœ¬åœ°
    pub fn with_config(config: EmbeddingConfig) -> Self;

    // åˆå§‹åŒ–ï¼ˆAPI å¤±è´¥è‡ªåŠ¨å›é€€åˆ°æœ¬åœ°ï¼‰
    pub async fn initialize(&mut self) -> Result<()>;

    // åµŒå…¥æ–‡æœ¬
    pub async fn embed(&self, text: &str) -> Result<Vec<f32>>;
    pub async fn embed_batch(&self, texts: &[String]) -> Result<Vec<Vec<f32>>>;

    // åŒæ­¥ç‰ˆæœ¬ï¼ˆä»…æœ¬åœ°æ¨¡å¼ï¼‰
    pub fn embed_sync(&self, text: &str) -> Result<Vec<f32>>;

    // è¾…åŠ©æ–¹æ³•
    pub fn backend_name(&self) -> String;
    pub fn embedding_dim(&self) -> usize;
}
```

### æ”¯æŒçš„åµŒå…¥æ¨¡å‹

| åç«¯ | æ¨¡å‹ | ç»´åº¦ | ç‰¹ç‚¹ |
|------|-----|------|------|
| **æœ¬åœ°** | all-MiniLM-L6-v2 | 384 | ç¦»çº¿å¯ç”¨ï¼Œå¿«é€Ÿ |
| **OpenAI** | text-embedding-3-small | 1536 | é«˜è´¨é‡ï¼Œéœ€ API Key |
| **OpenAI** | text-embedding-3-large | 3072 | æœ€é«˜è´¨é‡ |
| **Ollama** | nomic-embed-text | 768 | æœ¬åœ°æœåŠ¡ï¼Œå…è´¹ |
| **Ollama** | mxbai-embed-large | 1024 | æœ¬åœ°é«˜è´¨é‡ |

### å¿«é€Ÿå¼€å§‹ç¤ºä¾‹

```rust
use engram_lib::ai::embedding::{TextEmbedder, EmbeddingConfig};

// æ–¹å¼ 1: æœ¬åœ°æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
let mut embedder = TextEmbedder::new();
embedder.initialize().await?;

// æ–¹å¼ 2: OpenAI API
let mut embedder = TextEmbedder::with_config(
    EmbeddingConfig::openai("sk-...")
);
embedder.initialize().await?;  // å¤±è´¥ä¼šè‡ªåŠ¨å›é€€åˆ°æœ¬åœ°

// æ–¹å¼ 3: Ollama
let mut embedder = TextEmbedder::with_config(
    EmbeddingConfig::ollama("nomic-embed-text")
);
embedder.initialize().await?;

// åµŒå…¥æ–‡æœ¬
let vec = embedder.embed("hello world").await?;
let vecs = embedder.embed_batch(&texts).await?;

println!("Backend: {}", embedder.backend_name());
println!("Dimension: {}", embedder.embedding_dim());
```

### å½“å‰å®ç°çŠ¶æ€ (Phase 2 M2.2 å®Œæˆ)

- **æ–‡ä»¶**: `src-tauri/src/ai/embedding.rs` (~500 è¡Œ)
- **æ ¸å¿ƒç»“æ„**:
  - `TextEmbedder` - åŒåç«¯æ–‡æœ¬åµŒå…¥å™¨
  - `EmbeddingConfig` - çµæ´»é…ç½®ç³»ç»Ÿ
  - `EmbeddingQueue` - æ‰¹å¤„ç†é˜Ÿåˆ—

- **å…³é”®ç‰¹æ€§**:
  - OpenAI å…¼å®¹ API æ”¯æŒ
  - è‡ªåŠ¨å›é€€åˆ°æœ¬åœ°æ¨¡å‹
  - å¼‚æ­¥å’ŒåŒæ­¥ API
  - æ‰¹é‡åµŒå…¥ä¼˜åŒ–

---

## å‘é‡æœç´¢ä¸æ··åˆæœç´¢

### å‘é‡å­˜å‚¨è®¾è®¡

```sql
-- traces è¡¨æ–°å¢å­—æ®µ (M2.2.2 å®Œæˆ)
ALTER TABLE traces ADD COLUMN embedding BLOB;  -- å‘é‡ä»¥ BLOB å½¢å¼å­˜å‚¨

-- å‘é‡æ ¼å¼: ä½¿ç”¨ bincode åºåˆ—åŒ–ä¸ºäºŒè¿›åˆ¶
-- Vec<f32> -> bincode ç¼–ç  -> BLOB
```

### å‘é‡æœç´¢å®ç° (M2.2.2)

å‚è§ `llmdoc/architecture/data-flow.md` ä¸­çš„å‘é‡æœç´¢éƒ¨åˆ†ã€‚

### æ··åˆæœç´¢ - RRF èåˆ (M2.2.3 å®Œæˆ)

ç»“åˆå…¨æ–‡æœç´¢ (FTS5) å’Œå‘é‡æœç´¢ï¼Œä½¿ç”¨ RRF (Reciprocal Rank Fusion) èåˆç®—æ³•è¿›è¡Œç»“æœæ’åºã€‚

---

## æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

### 1. è‡ªåŠ¨æ£€æµ‹ + é»˜è®¤é…ç½®

```rust
// è‡ªåŠ¨æ£€æµ‹æœ¬åœ°æœåŠ¡ï¼Œå¼€ç®±å³ç”¨
let mut engine = VlmEngine::auto_detect().await.expect(
    "No local VLM service detected.\n\
     Please install Ollama: https://ollama.com/download"
);
engine.initialize().await?;
```

### 2. æ‰¹å¤„ç†

```rust
// æ¯ 10 å¸§è¿›è¡Œä¸€æ¬¡æ‰¹é‡åµŒå…¥
const EMBEDDING_BATCH_SIZE: usize = 10;

impl EmbeddingQueue {
    fn enqueue(&mut self, text: String, callback: Callback) {
        self.queue.push((text, callback));

        if self.queue.len() >= EMBEDDING_BATCH_SIZE {
            self.flush();
        }
    }

    fn flush(&mut self) {
        let texts: Vec<_> = self.queue.iter().map(|(t, _)| t.clone()).collect();
        let embeddings = self.embedder.embed_batch(&texts).unwrap();

        for ((_, callback), emb) in self.queue.drain(..).zip(embeddings) {
            callback(emb);
        }
    }
}
```

### 3. ç¡¬ä»¶é€‚é…

| ç¡¬ä»¶é…ç½® | VLM é€‰æ‹© | åµŒå…¥ç²¾åº¦ | æ¨èç”¨é€” |
|---------|---------|---------|---------|
| é«˜ç«¯ (16GB+, GPU) | GPT-4V æˆ– QwenVL-8B | FP32 | é«˜ç²¾åº¦ã€å®æ—¶å¤„ç† |
| ä¸­ç«¯ (8-16GB) | Qwen3-VL-4B (Ollama) | FP32 | å¹³è¡¡æ€§èƒ½å’Œè´¨é‡ |
| ä½ç«¯ (<8GB) | Qwen3-VL-4B Q2_K é‡åŒ– | FP16 | æœ‰é™èµ„æºä¸‹å¯ç”¨ |

### 4. ç¼“å­˜ç­–ç•¥

```rust
// å›¾ç‰‡å“ˆå¸Œç¼“å­˜ï¼Œé¿å…é‡å¤åˆ†æ
struct VlmCache {
    lru: LRUCache<ImageHash, ScreenDescription>,
    max_size: usize,
}

impl VlmCache {
    fn get_or_analyze(&mut self, image: &RgbImage, engine: &VlmEngine) -> Result<ScreenDescription> {
        let hash = hash_image(image);
        if let Some(cached) = self.lru.get(&hash) {
            return Ok(cached.clone());
        }

        let desc = engine.analyze_screen(image).await?;
        self.lru.insert(hash, desc.clone());
        Ok(desc)
    }
}
```

---

## SummarizerTask - å‘¨æœŸæ‘˜è¦ç”Ÿæˆ (M3.2)

### è®¾è®¡ç›®æ ‡

1. **è‡ªåŠ¨åŒ–æ‘˜è¦** - æ— éœ€ç”¨æˆ·æ‰‹åŠ¨è§¦å‘ï¼Œå®šæœŸè‡ªåŠ¨ç”Ÿæˆ
2. **å¼‚æ­¥å¤„ç†** - ä¸é˜»å¡ä¸»ç¨‹åºå’Œ VLM åˆ†æ
3. **å†…å­˜èšåˆ** - å°†ç¦»æ•£çš„ traces æ‘˜è¦ä¸ºè¿è´¯çš„è®°å¿†
4. **å‘é‡åŒ–** - æ‘˜è¦æœ¬èº«ä¹Ÿè¢«å‘é‡åŒ–ï¼Œæ”¯æŒè¯­ä¹‰æœç´¢
5. **å¯é…ç½®** - æ‘˜è¦ç”Ÿæˆé—´éš”å¯è°ƒæ•´

### SummarizerTask ç»“æ„ä½“

```rust
pub struct SummarizerTask {
    db: Arc<Database>,
    embedder: Arc<RwLock<TextEmbedder>>,
    config: SummarizerConfig,
    is_running: Arc<AtomicBool>,
    generated_count: Arc<AtomicU64>,
}

pub struct SummarizerConfig {
    pub interval_ms: u64,      // ç”Ÿæˆé—´éš”ï¼ˆé»˜è®¤ 900000ms = 15åˆ†é’Ÿï¼‰
    pub lookback_minutes: u64, // å›é¡¾æ—¶é—´èŒƒå›´ï¼ˆé»˜è®¤ 30 åˆ†é’Ÿï¼‰
    pub enabled: bool,
}

pub struct SummaryRecord {
    pub id: i32,
    pub start_time: i64,
    pub end_time: i64,
    pub summary_type: String,  // "15min", "1hour", "1day"
    pub content: String,       // Markdown æ ¼å¼æ‘˜è¦
    pub structured_data: String, // JSON: {topics, entities, links}
    pub embedding: Vec<f32>,   // 384 ç»´å‘é‡
    pub trace_count: i32,
}
```

### æ‰§è¡Œæµç¨‹

```
1. å¯åŠ¨åå°ä»»åŠ¡
   â””â”€ åˆ›å»º Tokio å¼‚æ­¥ä»»åŠ¡ï¼Œè®¾ç½®å®šæ—¶å™¨

2. æ¯ä¸ªå‘¨æœŸ (15 åˆ†é’Ÿ)
   â”œâ”€ æ£€æŸ¥æ˜¯å¦å¯ç”¨
   â”œâ”€ æŸ¥è¯¢æœ€è¿‘ lookback_minutes å†…çš„ traces
   â”œâ”€ æ£€æŸ¥æ•°é‡æ˜¯å¦è¶³å¤Ÿï¼ˆè‡³å°‘ 5 æ¡ï¼‰
   â””â”€ è‹¥è¶³å¤Ÿï¼Œæ‰§è¡Œæ‘˜è¦ç”Ÿæˆ

3. æ‘˜è¦ç”Ÿæˆæµç¨‹
   â”œâ”€ æ„å»ºä¸Šä¸‹æ–‡ï¼šæå– traces çš„ ocr_text å’Œ app_name
   â”œâ”€ è°ƒç”¨ LLM ç”Ÿæˆæ‘˜è¦ï¼ˆä½¿ç”¨ç³»ç»Ÿ promptï¼‰
   â”œâ”€ è§£æ LLM å“åº”ï¼ˆMarkdown + JSONï¼‰
   â”œâ”€ ç”ŸæˆåµŒå…¥å‘é‡ (MiniLM)
   â””â”€ å­˜å‚¨åˆ° summaries è¡¨

4. LLM Prompt ç¤ºä¾‹
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ è¯·æ€»ç»“ä»¥ä¸‹ç”¨æˆ·æ´»åŠ¨è®°å½•ï¼ˆ30åˆ†é’Ÿï¼‰ï¼š  â”‚
   â”‚                                   â”‚
   â”‚ æ—¶é—´è½´ï¼š                          â”‚
   â”‚ - 14:00-14:10: VS Code ç¼–ç¨‹      â”‚
   â”‚ - 14:10-14:25: Chrome æµè§ˆ       â”‚
   â”‚ - 14:25-14:30: Slack èŠå¤©        â”‚
   â”‚                                   â”‚
   â”‚ è¯·ä»¥ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼š          â”‚
   â”‚ {                                 â”‚
   â”‚   "summary": "ç”¨æˆ·èŠ±30åˆ†é’Ÿ...",   â”‚
   â”‚   "topics": ["ç¼–ç¨‹", "ç ”ç©¶"],     â”‚
   â”‚   "entities": ["React", "API"],   â”‚
   â”‚   "sentiment": "ä¸“æ³¨"             â”‚
   â”‚ }                                 â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### AppState é›†æˆ

```rust
pub struct AppState {
    pub db: Arc<Database>,
    pub daemon: Arc<RwLock<EngramDaemon>>,
    pub vlm: Arc<RwLock<Option<VlmEngine>>>,
    pub embedder: Arc<RwLock<TextEmbedder>>,
    pub vlm_task: Arc<RwLock<VlmTask>>,
    pub summarizer_task: Arc<RwLock<Option<SummarizerTask>>>,  // M3.2 æ–°å¢
}

// åº”ç”¨åˆå§‹åŒ–æ—¶
impl AppState {
    pub async fn new() -> anyhow::Result<Self> {
        // ... åˆå§‹åŒ–å…¶ä»–éƒ¨åˆ† ...

        // åˆ›å»º SummarizerTaskï¼ˆé»˜è®¤å¯ç”¨ï¼‰
        let summarizer_task = Arc::new(RwLock::new(
            SummarizerTask::new(
                db.clone(),
                embedder.clone(),
                SummarizerConfig::default(),
            )
        ));

        // AI åˆå§‹åŒ–æˆåŠŸåå¯åŠ¨æ‘˜è¦ä»»åŠ¡
        if vlm_initialized && embedder_ready {
            let mut task = state.summarizer_task.write().await;
            task.start()?;
            info!("Summarizer task started");
        }

        Ok(state)
    }
}
```

### æ€§èƒ½ç‰¹æ€§

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| **ç”Ÿæˆé—´éš”** | é»˜è®¤ 15 åˆ†é’Ÿï¼Œå¯é…ç½® |
| **å›é¡¾èŒƒå›´** | é»˜è®¤ 30 åˆ†é’Ÿ |
| **LLM è°ƒç”¨** | æ”¯æŒæœ¬åœ° LLM å’Œäº‘ç«¯ API |
| **å‘é‡åŒ–** | è‡ªåŠ¨ä½¿ç”¨ MiniLM ç”Ÿæˆ 384d å‘é‡ |
| **æ•°æ®æŒä¹…åŒ–** | å…¨éƒ¨å­˜å‚¨åˆ° SQLiteï¼Œæ”¯æŒåç»­æ£€ç´¢ |

---

## Chat - åŸºäºè®°å¿†çš„äº¤äº’å¯¹è¯ (M3.2)

### è®¾è®¡ç›®æ ‡

1. **ä¸Šä¸‹æ–‡æ„ŸçŸ¥** - åŸºäºç”¨æˆ·æ´»åŠ¨å†å²è¿›è¡Œå¯¹è¯
2. **çµæ´»è¿‡æ»¤** - æ”¯æŒæ—¶é—´èŒƒå›´å’Œåº”ç”¨ç±»å‹è¿‡æ»¤
3. **æ¥æºå¼•ç”¨** - æ˜¾ç¤ºå›å¤çš„æ•°æ®æ¥æº
4. **é¢„è®¾é—®é¢˜** - æä¾›å¸¸ç”¨æŸ¥è¯¢æ¨¡æ¿
5. **å‘é‡åŠ é€Ÿ** - åˆ©ç”¨ sqlite-vec KNN å¿«é€Ÿæ£€ç´¢ä¸Šä¸‹æ–‡

### Chat æ•°æ®æµ

```
ç”¨æˆ·è¾“å…¥æŸ¥è¯¢ + è¿‡æ»¤æ¡ä»¶
    â†“
[æŸ¥è¯¢é¢„å¤„ç†]
  â”œâ”€ è§£ææ—¶é—´èŒƒå›´ (ä»Šå¤©/æœ¬å‘¨/æœ¬æœˆ/å…¨éƒ¨)
  â”œâ”€ è§£æåº”ç”¨è¿‡æ»¤ (å¤šé€‰)
  â””â”€ å‡†å¤‡å‘é‡æœç´¢
    â†“
[å‘é‡ä¸Šä¸‹æ–‡æ£€ç´¢] (M3.2 sqlite-vec ä¼˜åŒ–)
  â”œâ”€ åµŒå…¥ç”¨æˆ·æŸ¥è¯¢ (384d MiniLM å‘é‡)
  â”œâ”€ ä½¿ç”¨ sqlite-vec KNN æœç´¢ç›¸å…³ traces
  â”‚  â””â”€ WHERE embedding MATCH :query AND k = 20
  â”œâ”€ è¿‡æ»¤æ—¶é—´èŒƒå›´å’Œåº”ç”¨
  â””â”€ è¿”å›å‰ 5 æ¡æœ€ç›¸å…³çš„ traces
    â†“
[æ„å»ºå¯¹è¯ä¸Šä¸‹æ–‡]
  â”œâ”€ æ±‡æ€» traces çš„ ocr_text
  â”œâ”€ æ·»åŠ  summariesï¼ˆå¦‚æœå­˜åœ¨ï¼‰
  â””â”€ ç»„ç»‡ä¸º prompt çš„ä¸Šä¸‹æ–‡
    â†“
[VLM æ–‡æœ¬å¯¹è¯]
  â”œâ”€ è°ƒç”¨ VlmEngine::chat(prompt)
  â”œâ”€ è¿”å› AI å›å¤æ–‡æœ¬
  â””â”€ è®°å½•å¼•ç”¨çš„ trace IDs
    â†“
[å‰ç«¯å±•ç¤º]
  â”œâ”€ æ˜¾ç¤º AI å›å¤
  â”œâ”€ æ˜¾ç¤ºå¼•ç”¨æ¥æºï¼ˆç‚¹å‡»è·³è½¬æˆªå›¾ï¼‰
  â””â”€ æ¶ˆæ¯å†å²ä¿å­˜
```

### å…³é”®å‘½ä»¤

**åç«¯å‘½ä»¤**:

```rust
// è·å–å¯ç”¨åº”ç”¨åˆ—è¡¨
pub async fn get_available_apps(
    start_time: i64,
    end_time: i64,
) -> Result<Vec<String>, String>

// åŸºäºè®°å¿†çš„å¯¹è¯
pub async fn chat_with_memory(
    query: String,
    time_range: TimeRange,      // Today/Week/Month/All
    app_filters: Vec<String>,   // å¯é€‰åº”ç”¨è¿‡æ»¤
    max_context: usize,         // æœ€å¤šè¿”å› context æ¡æ•°ï¼ˆé»˜è®¤ 10ï¼‰
) -> Result<ChatResponse, String>
```

**æ•°æ®ç»“æ„**:

```rust
pub struct ChatRequest {
    pub query: String,
    pub time_range: TimeRange,
    pub app_filters: Vec<String>,
    pub max_context: usize,
}

pub struct ChatResponse {
    pub id: String,                    // å¯¹è¯ ID
    pub message: String,               // AI å›å¤æ–‡æœ¬
    pub sources: Vec<TraceReference>,  // å¼•ç”¨çš„ trace
    pub summaries_used: Vec<i32>,      // ä½¿ç”¨çš„ summary IDs
    pub created_at: i64,
}

pub struct TraceReference {
    pub trace_id: i32,
    pub timestamp: i64,
    pub app_name: Option<String>,
    pub preview_text: String,  // ocr_text çš„å‰ 100 å­—
}
```

### å‰ç«¯ Chat é¡µé¢

**è·¯ç”±**: `/chat`

**åŠŸèƒ½**:
1. **æ—¶é—´èŒƒå›´ç­›é€‰** - ä»Šå¤© / æœ¬å‘¨ / æœ¬æœˆ / å…¨éƒ¨æ—¶é—´
2. **åº”ç”¨å¤šé€‰è¿‡æ»¤** - ä» `get_available_apps()` åŠ¨æ€è·å–
3. **é¢„è®¾é—®é¢˜** - å¦‚ï¼š
   - "æˆ‘ä»Šå¤©åšäº†ä»€ä¹ˆ?"
   - "èŠ±æœ€å¤šæ—¶é—´çš„æ˜¯ä»€ä¹ˆ?"
   - "æ‰“å¼€äº†å“ªäº›é¡¹ç›®æ–‡ä»¶?"
   - "æœ‰å“ªäº›é‡è¦çš„ä¼šè®®?"

4. **æ¶ˆæ¯å†å²** - æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯å’Œ AI å›å¤
5. **æ¥æºå¼•ç”¨** -
   - æ˜¾ç¤ºå¼•ç”¨çš„ trace æ•°é‡
   - ç‚¹å‡»å¯è·³è½¬åˆ°å¯¹åº”æ—¶é—´çš„æˆªå›¾
   - é«˜äº®å¼•ç”¨æ–‡æœ¬

**UI äº¤äº’æµ**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ” Chat - ä¸è®°å¿†å¯¹è¯        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ—¶é—´èŒƒå›´: [ä»Šå¤© v]           â”‚
â”‚ åº”ç”¨è¿‡æ»¤: [+é€‰æ‹©åº”ç”¨]        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å¿«é€Ÿé—®é¢˜:                    â”‚
â”‚ [æˆ‘ä»Šå¤©åšäº†ä»€ä¹ˆ?]           â”‚
â”‚ [èŠ±æœ€å¤šæ—¶é—´çš„æ˜¯ä»€ä¹ˆ?]       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ¶ˆæ¯å†å²:                    â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ ä½ : æˆ‘ä»Šå¤©çš„å·¥ä½œ       â”‚  â”‚
â”‚ â”‚                        â”‚  â”‚
â”‚ â”‚ AI: åŸºäºä½ çš„æ´»åŠ¨...   â”‚  â”‚
â”‚ â”‚ ğŸ“Œ å¼•ç”¨ 5 æ¡è®°å½•      â”‚  â”‚
â”‚ â”‚ [æ˜¾ç¤ºæ¥æº]             â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [è¾“å…¥æ¡†: é—®æˆ‘ä»»ä½•å…³äºä»Šå¤©...] â”‚
â”‚ [å‘é€]                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### sqlite-vec é›†æˆ

Chat å‘½ä»¤åˆ©ç”¨ sqlite-vec çš„é«˜æ•ˆå‘é‡æœç´¢ï¼š

```rust
// VLM æ–‡æœ¬å¯¹è¯ï¼ˆä¸å¸¦å›¾åƒï¼‰
impl VlmEngine {
    pub async fn chat(&self, prompt: &str) -> Result<String> {
        // æ„å»ºçº¯æ–‡æœ¬å¯¹è¯ prompt
        let messages = vec![
            {
                "role": "system",
                "content": "ä½ æ˜¯ç”¨æˆ·çš„ä¸ªäººåŠ©æ‰‹ï¼ŒåŸºäºç”¨æˆ·çš„æ´»åŠ¨è®°å½•å›ç­”é—®é¢˜ã€‚..."
            },
            {
                "role": "user",
                "content": prompt
            }
        ];

        // è°ƒç”¨ OpenAI å…¼å®¹ API
        let response = self.client
            .post(&format!("{}/v1/chat/completions", self.endpoint))
            .json(&request)
            .send()
            .await?;

        // è§£æå“åº”
        let result = response.json::<ChatCompletionResponse>().await?;
        Ok(result.choices[0].message.content.clone())
    }
}

// æ•°æ®åº“å±‚ï¼šä½¿ç”¨ sqlite-vec KNN æ£€ç´¢
impl Database {
    pub fn search_by_embedding(
        &self,
        query_vector: &[f32],
        k: i32,
        filters: SearchFilters,
    ) -> Result<Vec<Trace>> {
        // sqlite-vec KNN æŸ¥è¯¢
        let mut stmt = self.db.prepare(
            "SELECT t.* FROM traces_vec vec
             JOIN traces t ON vec.trace_id = t.id
             WHERE vec.embedding MATCH ?1 AND k = ?2
             ORDER BY distance LIMIT ?3"
        )?;

        let results = stmt.query_map(
            params![&query_vector, k, filters.limit],
            |row| Trace::from_row(row)
        )?;

        // åº”ç”¨æ—¶é—´å’Œåº”ç”¨è¿‡æ»¤
        results
            .filter_map(|r| r.ok())
            .filter(|t| filters.matches(t))
            .collect()
    }
}
```

### æ€§èƒ½ç‰¹æ€§

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| **æ£€ç´¢é€Ÿåº¦** | sqlite-vec KNN 10-50msï¼ˆ10000+ tracesï¼‰ |
| **ä¸Šä¸‹æ–‡å¤§å°** | é»˜è®¤ 10 æ¡ traces + summaries |
| **å¹¶å‘æ”¯æŒ** | å¤šç”¨æˆ·åŒæ—¶å¯¹è¯ï¼Œå¼‚æ­¥å¤„ç† |
| **ç¼“å­˜ç­–ç•¥** | åº”ç”¨åˆ—è¡¨ç¼“å­˜ï¼Œå‡å°‘æ•°æ®åº“æŸ¥è¯¢ |
